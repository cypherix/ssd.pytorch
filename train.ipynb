{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cypherix/ssd.pytorch/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kG2o_MYkXsgC",
        "colab_type": "code",
        "outputId": "f77e94b1-241f-4941-8844-e271b0ca304a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G75AQ3DsX02u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/My Drive/try')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qr_C0BA8XjJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from data import *\n",
        "from utils.augmentations import SSDAugmentation\n",
        "from layers.modules import MultiBoxLoss\n",
        "from ssd import build_ssd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDz-tIAHXjJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gciGnEcXjJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def str2bool(v):\n",
        "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfKQExqWXjJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cfg = pedestrian\n",
        "batch_size = 16\n",
        "gamma = 0.1\n",
        "dataset_root = VOC_ROOT\n",
        "save_folder = 'weights/'\n",
        "basenet = 'vgg16_reducedfc.pth'\n",
        "lr = 1e-4\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGcYUTiFXjJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(start_iter=0):\n",
        "    \n",
        "    #Dataset\n",
        "    dataset = VOCDetection(root = dataset_root,transform=SSDAugmentation(cfg['min_dim'], MEANS))\n",
        "    \n",
        "    #Building ssd\n",
        "    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n",
        "    net = ssd_net\n",
        "    \n",
        "    #Activating Cuda\n",
        "    net = torch.nn.DataParallel(ssd_net)\n",
        "    cudnn.benchmark = True\n",
        "    \n",
        "    print('Resuming training, loading {}...'.format('weights/ssd300_VOC_1000.pth'))\n",
        "    ssd_net.load_weights('weights/ssd300_VOC_'+str(start_iter)+'.pth')\n",
        "    \n",
        "    #Loading weights\n",
        "    #vgg_weights = torch.load(save_folder + basenet)\n",
        "    #print('Loading base network...')\n",
        "    #ssd_net.vgg.load_state_dict(vgg_weights)\n",
        "    #print('Initializing weights...')\n",
        "    # initialize newly added layers' weights with xavier method\n",
        "    #ssd_net.extras.apply(weights_init)\n",
        "    #ssd_net.loc.apply(weights_init)\n",
        "    #ssd_net.conf.apply(weights_init)\n",
        "    \n",
        "    net = net.cuda()\n",
        "    \n",
        "    #Loss and optimization\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum = momentum,weight_decay = weight_decay)\n",
        "    criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,False, True)\n",
        "    \n",
        "    net.train()\n",
        "    # loss counters\n",
        "    loc_loss = 0\n",
        "    conf_loss = 0\n",
        "    epoch = 0\n",
        "    print('Loading the dataset...')\n",
        "\n",
        "    epoch_size = len(dataset) // batch_size\n",
        "    print('Training SSD on:', dataset.name)\n",
        "    \n",
        "    step_index = 0\n",
        "    \n",
        "    #Loading Dataset    \n",
        "    data_loader = data.DataLoader(dataset, batch_size, num_workers=4, shuffle=True,\n",
        "                                  collate_fn=detection_collate, pin_memory=True)\n",
        "    \n",
        "    # create batch iterator\n",
        "    batch_iterator = iter(data_loader)\n",
        "    for iteration in range(start_iter, cfg['max_iter']):\n",
        "        #if iteration in cfg['lr_steps']:\n",
        "        #    step_index += 1\n",
        "        #    adjust_learning_rate(optimizer, gamma, step_index)\n",
        "\n",
        "        # load train data\n",
        "        try:\n",
        "            images, targets = next(batch_iterator)\n",
        "        except StopIteration:\n",
        "            batch_iterator = iter(data_loader)\n",
        "            images, targets = next(batch_iterator)\n",
        "        \n",
        "        images = Variable(images.cuda())\n",
        "        with torch.no_grad():\n",
        "            targets = [Variable(ann.cuda()) for ann in targets]\n",
        "        \n",
        "        # forward\n",
        "        t0 = time.time()\n",
        "        out = net(images)\n",
        "        \n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss_l, loss_c = criterion(out, targets)\n",
        "        loss = loss_l + loss_c\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t1 = time.time()\n",
        "        loc_loss += loss_l.item()\n",
        "        conf_loss += loss_c.item()\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print('timer: %.4f sec.' % (t1 - t0))\n",
        "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.item()), end=' ')\n",
        "\n",
        "        \n",
        "        if iteration != 0 and iteration % 1000 == 0:\n",
        "            print('\\nSaving state, iter:', iteration)\n",
        "            torch.save(ssd_net.state_dict(), 'weights/ssd300_VOC_' + repr(iteration) + '.pth')\n",
        "    \n",
        "    torch.save(ssd_net.state_dict(),\n",
        "               save_folder + 'ssd_person.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ki-eqCh2XjJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, gamma, step):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
        "        specified step\n",
        "    # Adapted from PyTorch Imagenet example:\n",
        "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
        "    \"\"\"\n",
        "    lr = lr * (gamma ** (step))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFvQ7UNFXjKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier(param):\n",
        "    init.xavier_uniform_(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxHttn5zXjKF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        xavier(m.weight.data)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "fp6pr_xbXjKJ",
        "colab_type": "code",
        "outputId": "854e7cd2-bae2-43aa-d1aa-97571157e8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2604
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    train(138000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resuming training, loading weights/ssd300_VOC_1000.pth...\n",
            "Loading weights into state dict...\n",
            "Finished!\n",
            "Loading the dataset...\n",
            "Training SSD on: VOC0712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timer: 19.3302 sec.\n",
            "iter 138000 || Loss: 1.8315 || \n",
            "Saving state, iter: 138000\n",
            "timer: 0.4816 sec.\n",
            "iter 138100 || Loss: 1.9744 || timer: 0.3870 sec.\n",
            "iter 138200 || Loss: 2.5221 || timer: 0.4103 sec.\n",
            "iter 138300 || Loss: 2.1575 || timer: 0.4117 sec.\n",
            "iter 138400 || Loss: 2.3497 || timer: 0.4177 sec.\n",
            "iter 138500 || Loss: 1.6133 || timer: 0.4502 sec.\n",
            "iter 138600 || Loss: 2.3512 || timer: 0.4471 sec.\n",
            "iter 138700 || Loss: 2.0656 || timer: 0.4534 sec.\n",
            "iter 138800 || Loss: 2.3042 || timer: 0.4324 sec.\n",
            "iter 138900 || Loss: 1.8358 || timer: 0.4391 sec.\n",
            "iter 139000 || Loss: 2.2822 || \n",
            "Saving state, iter: 139000\n",
            "timer: 0.4550 sec.\n",
            "iter 139100 || Loss: 2.5102 || timer: 0.4469 sec.\n",
            "iter 139200 || Loss: 2.6075 || timer: 0.4385 sec.\n",
            "iter 139300 || Loss: 2.1186 || timer: 0.4475 sec.\n",
            "iter 139400 || Loss: 2.1126 || timer: 0.4319 sec.\n",
            "iter 139500 || Loss: 2.9796 || timer: 0.4146 sec.\n",
            "iter 139600 || Loss: 2.3358 || timer: 0.4203 sec.\n",
            "iter 139700 || Loss: 1.9458 || timer: 0.4375 sec.\n",
            "iter 139800 || Loss: 2.1742 || timer: 0.4393 sec.\n",
            "iter 139900 || Loss: 2.4354 || timer: 0.4432 sec.\n",
            "iter 140000 || Loss: 2.1819 || \n",
            "Saving state, iter: 140000\n",
            "timer: 0.4209 sec.\n",
            "iter 140100 || Loss: 1.7834 || timer: 0.4180 sec.\n",
            "iter 140200 || Loss: 2.3059 || timer: 0.4206 sec.\n",
            "iter 140300 || Loss: 2.3261 || timer: 0.4576 sec.\n",
            "iter 140400 || Loss: 2.4145 || timer: 0.4259 sec.\n",
            "iter 140500 || Loss: 1.9401 || timer: 0.4180 sec.\n",
            "iter 140600 || Loss: 2.9222 || timer: 0.4292 sec.\n",
            "iter 140700 || Loss: 1.7051 || timer: 0.4677 sec.\n",
            "iter 140800 || Loss: 2.1748 || timer: 0.4145 sec.\n",
            "iter 140900 || Loss: 1.8224 || timer: 0.4174 sec.\n",
            "iter 141000 || Loss: 2.0705 || \n",
            "Saving state, iter: 141000\n",
            "timer: 0.4505 sec.\n",
            "iter 141100 || Loss: 1.9584 || timer: 0.4301 sec.\n",
            "iter 141200 || Loss: 2.4184 || timer: 0.4500 sec.\n",
            "iter 141300 || Loss: 1.9056 || timer: 0.4209 sec.\n",
            "iter 141400 || Loss: 2.3847 || timer: 0.4566 sec.\n",
            "iter 141500 || Loss: 2.0941 || timer: 0.4176 sec.\n",
            "iter 141600 || Loss: 2.3776 || timer: 0.4187 sec.\n",
            "iter 141700 || Loss: 2.1634 || timer: 0.4279 sec.\n",
            "iter 141800 || Loss: 2.3170 || timer: 0.4134 sec.\n",
            "iter 141900 || Loss: 2.1339 || timer: 0.4560 sec.\n",
            "iter 142000 || Loss: 2.2392 || \n",
            "Saving state, iter: 142000\n",
            "timer: 0.4462 sec.\n",
            "iter 142100 || Loss: 2.4373 || timer: 0.4453 sec.\n",
            "iter 142200 || Loss: 2.3203 || timer: 0.4511 sec.\n",
            "iter 142300 || Loss: 1.5603 || timer: 0.4445 sec.\n",
            "iter 142500 || Loss: 1.9700 || timer: 0.4254 sec.\n",
            "iter 142600 || Loss: 2.1799 || timer: 0.4363 sec.\n",
            "iter 142700 || Loss: 1.9950 || timer: 0.4148 sec.\n",
            "iter 142800 || Loss: 1.5540 || timer: 0.4478 sec.\n",
            "iter 142900 || Loss: 2.4017 || timer: 0.4390 sec.\n",
            "iter 143000 || Loss: 2.1156 || \n",
            "Saving state, iter: 143000\n",
            "timer: 0.4519 sec.\n",
            "iter 143100 || Loss: 2.4456 || timer: 0.4190 sec.\n",
            "iter 143200 || Loss: 2.0900 || timer: 0.4521 sec.\n",
            "iter 143300 || Loss: 2.2747 || timer: 0.4296 sec.\n",
            "iter 143400 || Loss: 2.4284 || timer: 0.4426 sec.\n",
            "iter 143500 || Loss: 1.9368 || timer: 0.4498 sec.\n",
            "iter 143600 || Loss: 2.2791 || timer: 0.4291 sec.\n",
            "iter 143700 || Loss: 2.5768 || timer: 0.4424 sec.\n",
            "iter 143800 || Loss: 2.7364 || timer: 0.4437 sec.\n",
            "iter 143900 || Loss: 3.0188 || timer: 0.4160 sec.\n",
            "iter 144000 || Loss: 2.1076 || \n",
            "Saving state, iter: 144000\n",
            "timer: 0.4767 sec.\n",
            "iter 144100 || Loss: 2.0160 || timer: 0.4388 sec.\n",
            "iter 144200 || Loss: 1.8499 || timer: 0.4592 sec.\n",
            "iter 144300 || Loss: 2.2062 || timer: 0.4252 sec.\n",
            "iter 144400 || Loss: 2.8973 || timer: 0.4228 sec.\n",
            "iter 144500 || Loss: 2.3362 || timer: 0.4834 sec.\n",
            "iter 144600 || Loss: 2.1370 || timer: 0.4237 sec.\n",
            "iter 144700 || Loss: 2.3445 || timer: 0.4275 sec.\n",
            "iter 144800 || Loss: 2.0030 || timer: 0.4318 sec.\n",
            "iter 144900 || Loss: 2.0180 || timer: 0.4269 sec.\n",
            "iter 145000 || Loss: 1.9833 || \n",
            "Saving state, iter: 145000\n",
            "timer: 0.4537 sec.\n",
            "iter 145100 || Loss: 2.0552 || timer: 0.4386 sec.\n",
            "iter 145200 || Loss: 1.9344 || timer: 0.4505 sec.\n",
            "iter 145300 || Loss: 1.9920 || timer: 0.4399 sec.\n",
            "iter 145400 || Loss: 2.1245 || timer: 0.4292 sec.\n",
            "iter 145500 || Loss: 2.4053 || timer: 0.4204 sec.\n",
            "iter 145600 || Loss: 1.6951 || timer: 0.4245 sec.\n",
            "iter 145700 || Loss: 1.8104 || timer: 0.4199 sec.\n",
            "iter 145800 || Loss: 2.1070 || timer: 0.4351 sec.\n",
            "iter 145900 || Loss: 2.6718 || timer: 0.4261 sec.\n",
            "iter 146000 || Loss: 2.4152 || \n",
            "Saving state, iter: 146000\n",
            "timer: 0.4422 sec.\n",
            "iter 146100 || Loss: 2.1769 || timer: 0.4166 sec.\n",
            "iter 146200 || Loss: 2.1105 || timer: 0.4533 sec.\n",
            "iter 146300 || Loss: 2.0095 || timer: 0.4188 sec.\n",
            "iter 146400 || Loss: 2.8355 || timer: 0.4430 sec.\n",
            "iter 146500 || Loss: 1.6144 || timer: 0.4342 sec.\n",
            "iter 146600 || Loss: 2.6412 || timer: 0.4448 sec.\n",
            "iter 146700 || Loss: 1.6403 || timer: 0.4443 sec.\n",
            "iter 146800 || Loss: 1.7033 || timer: 0.4127 sec.\n",
            "iter 146900 || Loss: 1.9037 || timer: 0.5187 sec.\n",
            "iter 147000 || Loss: 2.1461 || \n",
            "Saving state, iter: 147000\n",
            "timer: 0.4442 sec.\n",
            "iter 147100 || Loss: 2.2870 || timer: 0.4280 sec.\n",
            "iter 147200 || Loss: 1.8277 || timer: 0.4259 sec.\n",
            "iter 147300 || Loss: 2.2373 || timer: 0.4243 sec.\n",
            "iter 147400 || Loss: 2.3387 || timer: 0.4370 sec.\n",
            "iter 147500 || Loss: 1.9156 || timer: 0.3888 sec.\n",
            "iter 147600 || Loss: 2.2483 || timer: 0.4534 sec.\n",
            "iter 147700 || Loss: 2.2434 || timer: 0.4175 sec.\n",
            "iter 147800 || Loss: 2.2995 || timer: 0.4544 sec.\n",
            "iter 147900 || Loss: 1.8516 || timer: 0.4147 sec.\n",
            "iter 148000 || Loss: 2.4609 || \n",
            "Saving state, iter: 148000\n",
            "timer: 0.4458 sec.\n",
            "iter 148100 || Loss: 2.0863 || timer: 0.4470 sec.\n",
            "iter 148200 || Loss: 2.1346 || timer: 0.4295 sec.\n",
            "iter 148300 || Loss: 2.5371 || timer: 0.4585 sec.\n",
            "iter 148400 || Loss: 1.9897 || timer: 0.4489 sec.\n",
            "iter 148500 || Loss: 2.1992 || timer: 0.4313 sec.\n",
            "iter 148600 || Loss: 1.6396 || timer: 0.4260 sec.\n",
            "iter 148700 || Loss: 1.9208 || timer: 0.4368 sec.\n",
            "iter 148800 || Loss: 2.4362 || timer: 0.4298 sec.\n",
            "iter 148900 || Loss: 2.0392 || timer: 0.4447 sec.\n",
            "iter 149000 || Loss: 2.2930 || \n",
            "Saving state, iter: 149000\n",
            "timer: 0.4348 sec.\n",
            "iter 149100 || Loss: 2.3359 || timer: 0.4205 sec.\n",
            "iter 149200 || Loss: 1.7774 || timer: 0.4241 sec.\n",
            "iter 149300 || Loss: 2.6542 || timer: 0.4240 sec.\n",
            "iter 149400 || Loss: 1.6833 || timer: 0.4453 sec.\n",
            "iter 149500 || Loss: 2.1719 || timer: 0.4321 sec.\n",
            "iter 149600 || Loss: 2.0569 || timer: 0.4280 sec.\n",
            "iter 149700 || Loss: 1.8277 || timer: 0.4196 sec.\n",
            "iter 149800 || Loss: 1.6881 || timer: 0.4622 sec.\n",
            "iter 149900 || Loss: 1.8760 || "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}